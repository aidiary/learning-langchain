{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part6 RAG-Fusion\n",
    "\n",
    "- 質問から異なるクエリを生成\n",
    "- 各クエリで文書を検索\n",
    "- 検索結果をRRFでランキング\n",
    "- ランキングされた文書をコンテキストにして回答を生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# Load blog\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://zenn.dev/knowledgesense/articles/47de9ead8029ba\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"Container_wide__ykGLh Container_common__figYY\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# Index\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='あなたは1つの入力クエリに基づいて複数の検索クエリを生成する役立つアシスタントです。\\n\\n以下に関連する複数の検索クエリを生成してください：{question}\\n\\n出力（4つのクエリ）:'), additional_kwargs={})])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"あなたは1つの入力クエリに基づいて複数の検索クエリを生成する役立つアシスタントです。\n",
    "\n",
    "以下に関連する複数の検索クエリを生成してください：{question}\n",
    "\n",
    "出力（4つのクエリ）:\"\"\"\n",
    "\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)\n",
    "prompt_rag_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. RAGとは何ですか？', '2. RAGの意味は何ですか？', '3. RAGの略は何ですか？', '4. RAGについて詳しく教えてください。']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries.invoke({\"question\": \"RAGとはなんですか？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGとは。なぜ必要なのか？\\nRAGとは、大雑把に言うと、ファイルを参照して回答できるLLM（例えばChatGPT）を作成するための方法です。RAGがなぜ必要なのかというと、通常のLLMでは、回答の正確性を向上させるのに限界があるからです。通常のLLMでは、事実と違う内容を勝手に捏造してしまったり（ハルシネーション）、そもそも学習データに含まれていない情報（例えば公開されていない社内の文書）については、回答することはできなかったりという限界があります。'),\n",
       "  Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの仕組み\\nこの記事をご覧のエンジニアの方であれば、既にご存知の内容かと思います。以下、チートシートの引用です。\\n「RAGでは、ユーザーが質問すると、まず外部データベースから関連するドキュメントを取得する。そのドキュメントと元々のユーザーの質問がセットされ、LLMに渡される。LLMは、この内容をもとに回答を生成する」\\n非常にシンプルな内容なので、この図と一緒に説明すれば、ビジネスサイドの方でも理解してもらえます。私個人的にも、似たような図を使って顧客や社内ビジネスサイドに説明していて、必ず理解してもらえる印象です。\\n\\nRAGの良さはこのシンプルさ、始めやすさなのですが、始めのうちは、なかなか思い通りの回答が得られません。この回答精度を上げようとすると、かなりの苦難が待っています...'),\n",
       "  Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの精度向上のために必要なこと\\nRAGの精度向上を試みる際に重要な要素は、以下の2点に分解できます。\\n\\nユーザーの質問に回答するために最も必要な（最も関連している）ドキュメント群を抽出すること\\n抽出してきたドキュメント群を最大限上手く活用して、正しい回答を生成すること\\n\\nこの2点は、上の「RAGの仕組み」で登場した画像の中の黄色い枠で囲まれている部分に該当します。\\n※具体的な手法は、今後の記事で紹介していきます\\n\\n RAGを使ってできること\\n\\n個人的には、実務でRAGを使っていて嬉しいポイントは\\n\\n情報不十分なとき、回答しないことができる\\n独自のドキュメントに基づいて回答できる（上の画像には含まれていませんが）'),\n",
       "  Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの品質計測\\n\\n「改善は計測から」なので、どのように評価するかは改善前に決めておく必要があります。\\n補足として、こちらの評価指標については、RAG評価ツールの「RAGAS」から、もう少し多くの指標が提案されています。[4]')],\n",
       " [Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの精度向上のために必要なこと\\nRAGの精度向上を試みる際に重要な要素は、以下の2点に分解できます。\\n\\nユーザーの質問に回答するために最も必要な（最も関連している）ドキュメント群を抽出すること\\n抽出してきたドキュメント群を最大限上手く活用して、正しい回答を生成すること\\n\\nこの2点は、上の「RAGの仕組み」で登場した画像の中の黄色い枠で囲まれている部分に該当します。\\n※具体的な手法は、今後の記事で紹介していきます\\n\\n RAGを使ってできること\\n\\n個人的には、実務でRAGを使っていて嬉しいポイントは\\n\\n情報不十分なとき、回答しないことができる\\n独自のドキュメントに基づいて回答できる（上の画像には含まれていませんが）'),\n",
       "  Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの品質計測\\n\\n「改善は計測から」なので、どのように評価するかは改善前に決めておく必要があります。\\n補足として、こちらの評価指標については、RAG評価ツールの「RAGAS」から、もう少し多くの指標が提案されています。[4]'),\n",
       "  Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの仕組み\\nこの記事をご覧のエンジニアの方であれば、既にご存知の内容かと思います。以下、チートシートの引用です。\\n「RAGでは、ユーザーが質問すると、まず外部データベースから関連するドキュメントを取得する。そのドキュメントと元々のユーザーの質問がセットされ、LLMに渡される。LLMは、この内容をもとに回答を生成する」\\n非常にシンプルな内容なので、この図と一緒に説明すれば、ビジネスサイドの方でも理解してもらえます。私個人的にも、似たような図を使って顧客や社内ビジネスサイドに説明していて、必ず理解してもらえる印象です。\\n\\nRAGの良さはこのシンプルさ、始めやすさなのですが、始めのうちは、なかなか思い通りの回答が得られません。この回答精度を上げようとすると、かなりの苦難が待っています...'),\n",
       "  Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGとは。なぜ必要なのか？\\nRAGとは、大雑把に言うと、ファイルを参照して回答できるLLM（例えばChatGPT）を作成するための方法です。RAGがなぜ必要なのかというと、通常のLLMでは、回答の正確性を向上させるのに限界があるからです。通常のLLMでは、事実と違う内容を勝手に捏造してしまったり（ハルシネーション）、そもそも学習データに含まれていない情報（例えば公開されていない社内の文書）については、回答することはできなかったりという限界があります。')],\n",
       " [Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの精度向上のために必要なこと\\nRAGの精度向上を試みる際に重要な要素は、以下の2点に分解できます。\\n\\nユーザーの質問に回答するために最も必要な（最も関連している）ドキュメント群を抽出すること\\n抽出してきたドキュメント群を最大限上手く活用して、正しい回答を生成すること\\n\\nこの2点は、上の「RAGの仕組み」で登場した画像の中の黄色い枠で囲まれている部分に該当します。\\n※具体的な手法は、今後の記事で紹介していきます\\n\\n RAGを使ってできること\\n\\n個人的には、実務でRAGを使っていて嬉しいポイントは\\n\\n情報不十分なとき、回答しないことができる\\n独自のドキュメントに基づいて回答できる（上の画像には含まれていませんが）'),\n",
       "  Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの仕組み\\nこの記事をご覧のエンジニアの方であれば、既にご存知の内容かと思います。以下、チートシートの引用です。\\n「RAGでは、ユーザーが質問すると、まず外部データベースから関連するドキュメントを取得する。そのドキュメントと元々のユーザーの質問がセットされ、LLMに渡される。LLMは、この内容をもとに回答を生成する」\\n非常にシンプルな内容なので、この図と一緒に説明すれば、ビジネスサイドの方でも理解してもらえます。私個人的にも、似たような図を使って顧客や社内ビジネスサイドに説明していて、必ず理解してもらえる印象です。\\n\\nRAGの良さはこのシンプルさ、始めやすさなのですが、始めのうちは、なかなか思い通りの回答が得られません。この回答精度を上げようとすると、かなりの苦難が待っています...'),\n",
       "  Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGとは。なぜ必要なのか？\\nRAGとは、大雑把に言うと、ファイルを参照して回答できるLLM（例えばChatGPT）を作成するための方法です。RAGがなぜ必要なのかというと、通常のLLMでは、回答の正確性を向上させるのに限界があるからです。通常のLLMでは、事実と違う内容を勝手に捏造してしまったり（ハルシネーション）、そもそも学習データに含まれていない情報（例えば公開されていない社内の文書）については、回答することはできなかったりという限界があります。'),\n",
       "  Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの品質計測\\n\\n「改善は計測から」なので、どのように評価するかは改善前に決めておく必要があります。\\n補足として、こちらの評価指標については、RAG評価ツールの「RAGAS」から、もう少し多くの指標が提案されています。[4]')],\n",
       " [Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの仕組み\\nこの記事をご覧のエンジニアの方であれば、既にご存知の内容かと思います。以下、チートシートの引用です。\\n「RAGでは、ユーザーが質問すると、まず外部データベースから関連するドキュメントを取得する。そのドキュメントと元々のユーザーの質問がセットされ、LLMに渡される。LLMは、この内容をもとに回答を生成する」\\n非常にシンプルな内容なので、この図と一緒に説明すれば、ビジネスサイドの方でも理解してもらえます。私個人的にも、似たような図を使って顧客や社内ビジネスサイドに説明していて、必ず理解してもらえる印象です。\\n\\nRAGの良さはこのシンプルさ、始めやすさなのですが、始めのうちは、なかなか思い通りの回答が得られません。この回答精度を上げようとすると、かなりの苦難が待っています...'),\n",
       "  Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの精度向上のために必要なこと\\nRAGの精度向上を試みる際に重要な要素は、以下の2点に分解できます。\\n\\nユーザーの質問に回答するために最も必要な（最も関連している）ドキュメント群を抽出すること\\n抽出してきたドキュメント群を最大限上手く活用して、正しい回答を生成すること\\n\\nこの2点は、上の「RAGの仕組み」で登場した画像の中の黄色い枠で囲まれている部分に該当します。\\n※具体的な手法は、今後の記事で紹介していきます\\n\\n RAGを使ってできること\\n\\n個人的には、実務でRAGを使っていて嬉しいポイントは\\n\\n情報不十分なとき、回答しないことができる\\n独自のドキュメントに基づいて回答できる（上の画像には含まれていませんが）'),\n",
       "  Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの品質計測\\n\\n「改善は計測から」なので、どのように評価するかは改善前に決めておく必要があります。\\n補足として、こちらの評価指標については、RAG評価ツールの「RAGAS」から、もう少し多くの指標が提案されています。[4]'),\n",
       "  Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGとは。なぜ必要なのか？\\nRAGとは、大雑把に言うと、ファイルを参照して回答できるLLM（例えばChatGPT）を作成するための方法です。RAGがなぜ必要なのかというと、通常のLLMでは、回答の正確性を向上させるのに限界があるからです。通常のLLMでは、事実と違う内容を勝手に捏造してしまったり（ハルシネーション）、そもそも学習データに含まれていない情報（例えば公開されていない社内の文書）については、回答することはできなかったりという限界があります。')]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = (generate_queries | retriever.map()).invoke({\"question\": \"RAGとはなんですか？\"})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "\n",
    "# RRF\n",
    "# https://www.perplexity.ai/search/reciprocal-rank-fusionnituitej-tUsKo.t4SCWzUFoogZ6dRg\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" 複数のランク付けされたドキュメントリストを受け取り、RRF（相互ランクフュージョン）の\n",
    "        計算に使う任意のパラメータkを使用する関数 \"\"\"\n",
    "    \n",
    "    # ユニークなドキュメントごとの融合されたスコアを保持する辞書を初期化\n",
    "    fused_scores = {}\n",
    "\n",
    "    # 各ランク付けされたドキュメントリストを順に処理\n",
    "    for docs in results:\n",
    "        # リスト内の各ドキュメントを、そのランク（リスト内での位置）とともに処理\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # ドキュメントをキーとして使用するために文字列形式に変換（ドキュメントがJSONにシリアライズできることを前提）\n",
    "            doc_str = dumps(doc)\n",
    "            # ドキュメントがまだ辞書に存在しない場合は、初期スコア0で追加\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # ドキュメントの現在のスコアを取得（存在する場合）\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # RRFの公式を使用してスコアを更新: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # 融合されたスコアに基づいてドキュメントを降順にソートし、最終的な再ランク付け結果を取得\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # ドキュメントとその融合スコアを含むタプルのリストとして、再ランク付けされた結果を返す\n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_715395/3747162137.py:27: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  (loads(doc), score)\n"
     ]
    }
   ],
   "source": [
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": \"RAGとはなんですか？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの精度向上のために必要なこと\\nRAGの精度向上を試みる際に重要な要素は、以下の2点に分解できます。\\n\\nユーザーの質問に回答するために最も必要な（最も関連している）ドキュメント群を抽出すること\\n抽出してきたドキュメント群を最大限上手く活用して、正しい回答を生成すること\\n\\nこの2点は、上の「RAGの仕組み」で登場した画像の中の黄色い枠で囲まれている部分に該当します。\\n※具体的な手法は、今後の記事で紹介していきます\\n\\n RAGを使ってできること\\n\\n個人的には、実務でRAGを使っていて嬉しいポイントは\\n\\n情報不十分なとき、回答しないことができる\\n独自のドキュメントに基づいて回答できる（上の画像には含まれていませんが）'),\n",
       "  0.06585580821434867),\n",
       " (Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの仕組み\\nこの記事をご覧のエンジニアの方であれば、既にご存知の内容かと思います。以下、チートシートの引用です。\\n「RAGでは、ユーザーが質問すると、まず外部データベースから関連するドキュメントを取得する。そのドキュメントと元々のユーザーの質問がセットされ、LLMに渡される。LLMは、この内容をもとに回答を生成する」\\n非常にシンプルな内容なので、この図と一緒に説明すれば、ビジネスサイドの方でも理解してもらえます。私個人的にも、似たような図を使って顧客や社内ビジネスサイドに説明していて、必ず理解してもらえる印象です。\\n\\nRAGの良さはこのシンプルさ、始めやすさなのですが、始めのうちは、なかなか思い通りの回答が得られません。この回答精度を上げようとすると、かなりの苦難が待っています...'),\n",
       "  0.06558258417063283),\n",
       " (Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGとは。なぜ必要なのか？\\nRAGとは、大雑把に言うと、ファイルを参照して回答できるLLM（例えばChatGPT）を作成するための方法です。RAGがなぜ必要なのかというと、通常のLLMでは、回答の正確性を向上させるのに限界があるからです。通常のLLMでは、事実と違う内容を勝手に捏造してしまったり（ハルシネーション）、そもそも学習データに含まれていない情報（例えば公開されていない社内の文書）については、回答することはできなかったりという限界があります。'),\n",
       "  0.06454173067076292),\n",
       " (Document(metadata={'source': 'https://zenn.dev/knowledgesense/articles/47de9ead8029ba', 'title': 'Zenn'}, page_content='RAGの品質計測\\n\\n「改善は計測から」なので、どのように評価するかは改善前に決めておく必要があります。\\n補足として、こちらの評価指標については、RAG評価ツールの「RAGAS」から、もう少し多くの指標が提案されています。[4]'),\n",
       "  0.06426850662704708)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回答: RAGとは、ファイルを参照して回答できるLLM（例えばChatGPT）を作成するための方法であり、通常のLLMでは回答の正確性を向上させるのに限界があるため必要とされる手法です。通常のLLMでは、事実と違う内容を勝手に捏造してしまったり、学習データに含まれていない情報については回答することができないという限界があります。\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from networkx import laplacian_matrix\n",
    "\n",
    "template = \"\"\"以下のコンテキストに基づいて以下の質問に答えてください。\n",
    "\n",
    "{context}\n",
    "\n",
    "質問: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(final_rag_chain.invoke({\"question\": \"RAGとはなんですか？\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-langchain-BRoTc1ZH-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
