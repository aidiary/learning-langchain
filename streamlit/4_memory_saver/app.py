import asyncio

from dotenv import load_dotenv
from graph import invoke_graph
from langchain_core.messages import AIMessage, HumanMessage

import streamlit as st

# https://github.com/shiv248/Streamlit-x-LangGraph-Cookbooks

load_dotenv()

st.title("StreamLit ğŸ¤ LangGraph")
st.markdown("#### å¯¾è©±å±¥æ­´ã®è¨˜æ†¶ã«MemorySaverã‚’ä½¿ã†")


if "messages" not in st.session_state:
    st.session_state["messages"] = [
        AIMessage(content="ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ")
    ]

# ã™ã¹ã¦ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æç”»ã™ã‚‹
for msg in st.session_state.messages:
    if type(msg) is AIMessage:
        st.chat_message("assistant").write(msg.content)
    if type(msg) is HumanMessage:
        st.chat_message("user").write(msg.content)

if prompt := st.chat_input():
    st.session_state.messages.append(HumanMessage(content=prompt))
    st.chat_message("user").write(prompt)

    with st.chat_message("assistant"):
        placeholder = st.container()

        # streamlitã¯ãƒ¦ãƒ¼ã‚¶ã”ã¨ã«ç‹¬ç«‹ãªã®ã§ã‚¹ãƒ¬ãƒƒãƒ‰IDã¯å›ºå®šã§ã‚‚ï¼¯ï¼«
        # åŒã˜configã‚’æ¸¡ã™ã“ã¨ã§ãƒ¡ãƒ¢ãƒªãŒç¶­æŒã•ã‚Œã‚‹
        config = {"configurable": {"thread_id": "1"}}

        # invoke_graphã«ã¯éå»ã®å¯¾è©±å±¥æ­´ã™ã¹ã¦ã§ã¯ãªãä»Šå›ã®ãƒ¦ãƒ¼ã‚¶å…¥åŠ›ã®ã¿ã‚’æ¸¡ã™
        # éå»ã®å¯¾è©±å±¥æ­´ã¯MemorySaverãŒä¿æŒã—ã¦ã„ã‚‹
        response = asyncio.run(invoke_graph(prompt, placeholder, config))

        st.session_state.messages.append(AIMessage(response))
