from dotenv import load_dotenv
from graph import invoke_graph
from langchain_core.messages import AIMessage, HumanMessage
from utils import get_streamlit_cb

import streamlit as st

# https://github.com/shiv248/Streamlit-x-LangGraph-Cookbooks

load_dotenv()

st.title("StreamLit ğŸ¤ LangGraph")
st.markdown("#### å…¬å¼ã®StreamlitCallbackHandlerã‚’ä½¿ã†å ´åˆ")


if "messages" not in st.session_state:
    st.session_state["messages"] = [
        AIMessage(content="ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ")
    ]

# ã™ã¹ã¦ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æç”»ã™ã‚‹
for msg in st.session_state.messages:
    if type(msg) is AIMessage:
        st.chat_message("assistant").write(msg.content)
    if type(msg) is HumanMessage:
        st.chat_message("user").write(msg.content)

if prompt := st.chat_input():
    st.session_state.messages.append(HumanMessage(content=prompt))
    st.chat_message("user").write(prompt)

    with st.chat_message("assistant"):
        # AIã®æœ€çµ‚å‡ºåŠ›ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
        msg_placeholder = st.empty()
        st_callback = get_streamlit_cb(st.empty())

        # graphã¯ãƒ¡ãƒ¢ãƒªã‚’æŒãŸãªã„ã®ã§éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã™ã¹ã¦ã‚ãŸã™
        response = invoke_graph(st.session_state.messages, [st_callback])

        last_msg = response["messages"][-1].content
        st.session_state.messages.append(AIMessage(content=last_msg))
        msg_placeholder.write(last_msg)
